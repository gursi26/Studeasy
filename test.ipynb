{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from utils import load_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = load_api_key(\"/Users/gursi/Desktop/openai-api.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_generator(chat_completion: openai.ChatCompletion, outline: dict[str, list[str]], level: str, subject: str):\n",
    "    prompt = engineer_prompt_note_gen(outline, level, subject)\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            # {\"role\": \"system\", \"content\":f\"Your are a {level} {subject} notes generator.\"},\n",
    "            {\"role\": \"system\", \"content\":f\"Your are a {level} {subject} notes generator. Generate notes in following format: \\n Topic heading: \\n \\t Notes...\"},\n",
    "            {\"role\": \"user\", \"content\":prompt}\n",
    "        ]\n",
    "    )\n",
    "    model_output = parse_results(model_output)\n",
    "    return model_output\n",
    "        \n",
    "    \n",
    "def engineer_prompt_note_gen(outline: dict[str, list[str]], level: str, subject: str):\n",
    "    prompt = f'Generate quick revision notes for me on the following topics for a {subject} course on a {level} level. Include all equations. Explain each variable and concept. Do not say \"sure, here are some notes..\".\\n\\n'\n",
    "    for topic in outline:\n",
    "        prompt += f\"- {topic}\\n\"\n",
    "        if outline[topic] is not None:\n",
    "            for subtopic in outline[topic]:\n",
    "                prompt += f\"    - {subtopic}\\n\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def parse_results(chatgpt_output: dict) -> str:\n",
    "    return chatgpt_output[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = load_api_key(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "chat_complete = openai.ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = {\n",
    "    \"Electromagnetism\":None,\n",
    "    \"Electricity\":[\n",
    "        \"Resistance\",\n",
    "        \"Energy and Power\",\n",
    "        \"Kirchoff Laws\",\n",
    "        \"Lenz laws\"\n",
    "    ],\n",
    "    \"Mechanics\": [\n",
    "        \"SUVAT equations\",\n",
    "        \"Terminal velocity\",\n",
    "        \"Friction and Drag\"\n",
    "    ]\n",
    "}\n",
    "output = note_generator(chat_complete, outline, \"High school\", \"Physics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electromagnetism:\n",
      "- Electromagnetic Force: A force of attraction or repulsion that acts between electrically charged particles or currents.\n",
      "- Electric charges: The fundamental property of matter that causes it to experience a force when placed in an electromagnetic field.\n",
      "- Magnetic field: A region around a magnetic material or moving electric charge within which the force of magnetism acts.\n",
      "Equation: F = qE + qv × B\n",
      "- Electromagnetic induction: A process where a conductor placed in a changing magnetic field causes a voltage to be induced across the conductor.\n",
      "Equation: ε = -dΦ/dt\n",
      "\n",
      "Electricity:\n",
      "- Resistance: The property of a material that opposes the flow of electric current through it.\n",
      "Equation: V = IR\n",
      "- Energy and Power: Energy is the ability to do work. Power is the rate at which work is done.\n",
      "Equations: E = Pt, P = VI\n",
      "- Kirchoff Laws: Two laws used for solving electrical circuits, namely the current law and the voltage law.\n",
      "Equations: ∑ I_in = ∑ I_out, ∑ V_loop = 0\n",
      "- Lenz laws: A law that states that an induced electric current in a conductor always flows in such a direction that it opposes the magnetic field that produced it.\n",
      "Equation: ε = −dΦ/dt\n",
      "\n",
      "Mechanics:\n",
      "- SUVAT equations: A set of equations that represent the relationship between distance, velocity, acceleration, and time\n",
      "Equations: v = u + at, s = ut + 1/2at^2, v^2 = u^2 + 2as, s = 1/2(u+v)t\n",
      "- Terminal velocity: The maximum speed that an object can reach when falling through a fluid (air or liquid)\n",
      "Equation: mg - kv = 0\n",
      "- Friction and Drag: Friction is a force that opposes motion between two surfaces in contact. Drag is a force that opposes motion through a fluid.\n",
      "Equations: F_friction = μN, F_drag = ½pv^2AC_d\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_results, parse_pdf, create_chat_object\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import openai\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_from_prompt(chat_completion: openai.ChatCompletion, prompt: str):\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to extract key words from text. Generic words should never be extracted, only topic specific words.\"},\n",
    "            {\"role\": \"user\", \"content\":f\"Extract the keywords from the following instruction. Output a single list of comma separated values only once. \\n\\n {prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    return output.split(\",\")\n",
    "\n",
    "def generate_single_summary(chat_completion: openai.ChatCompletion, input_text: str, summary_prompt: str) -> str:\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to summarize text based on a prompt. If relevant data is not found, return nothing.\"},\n",
    "            {\"role\": \"user\", \"content\":f\"{input_text} \\n\\n {summary_prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    return output\n",
    "\n",
    "def generate_summary(\n",
    "        chat_completion: openai.ChatCompletion,\n",
    "        text_body: str,\n",
    "        prompt: str,\n",
    "        buffer: int = 600\n",
    ") -> str:\n",
    "    keywords = extract_keywords_from_prompt(chat_completion, prompt)\n",
    "    keywords = [k.translate(str.maketrans('', '', string.punctuation)).strip().lower() for k in keywords]\n",
    "    print(f\"{len(keywords)} keywords found...\")\n",
    "    kw = []\n",
    "    [[kw.append(w) for w in word.split(\" \")] for word in keywords]\n",
    "    arr_text = np.array(text_body.lower().split())\n",
    "\n",
    "    print(\"Matching keywords in text...\")\n",
    "    idxs = np.array([])\n",
    "    max_idx = len(arr_text)\n",
    "    for keyw in kw:\n",
    "        kw_idxs = np.where(arr_text == keyw)[0] / max_idx\n",
    "        idxs = np.concatenate([idxs, kw_idxs])\n",
    "\n",
    "    print(\"Clustering...\")\n",
    "    kmeans = KMeans(n_clusters = len(keywords))\n",
    "    _ = kmeans.fit_predict(idxs.reshape(-1, 1))\n",
    "    centroid_idxs = list((kmeans.cluster_centers_ * len(arr_text)).astype(int).reshape(-1))\n",
    "\n",
    "    print(\"Generating summary...\")\n",
    "    summaries = []\n",
    "    for centroid_idx in centroid_idxs:\n",
    "        text_input = list(arr_text[max(0, centroid_idx - buffer):min(len(arr_text), centroid_idx + buffer)])\n",
    "        text_input = \" \".join(text_input)\n",
    "        summary = generate_single_summary(chat_completion, text_input, prompt)\n",
    "        summaries.append(summary)\n",
    "    summaries = \" \".join(summaries)\n",
    "    final_summary = generate_single_summary(chat_completion, summaries, prompt)\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "The study used an artificial neural system that separated image content from style using a VGG neural network and optimizing the white noise image through gradient descent. The loss function included a squared-error loss for feature representation and a mean-squared distance for style representation, with adjustable trade-off between the two. The model architecture consisted of 16 convolutional and 5 pooling layers, with max-pooling replaced by average pooling for image synthesis. Fully connected layers were not used, and the model was publicly available in the Caffe framework. The weighting factors for the contribution of each layer to the total loss were also included.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/Desktop/nst.pdf\")\n",
    "prompt = \"Summarize the loss function, optimization method and model architecture used in this study for me.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "Linear dependence and independence refer to whether a set of vectors can be expressed as linear combinations of each other or not. A basis for a subspace is a set of linearly independent vectors that span the subspace. Bases are not unique, but they all have the same number of vectors, called the dimension of the subspace, which tells us the maximum number of linearly independent vectors that can exist in the subspace. Linear independence is important in determining solutions to systems of linear equations and in finding bases and dimensions of vector spaces.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/desktop/223.pdf\")\n",
    "prompt = \"Summarize linear dependence and independence for me.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "The intertemporal budget line is a concept that represents the trade-off between current and future consumption. It shows the different combinations of present and future goods that a consumer can afford given their income and the interest rate. The slope of the line represents the opportunity cost of present consumption in terms of future consumption, and the intercepts represent the maximum levels of current and future consumption. The economic interpretation of the intercepts is that they represent the present value of future income or the future value of current income. A numerical example is provided to illustrate how the intertemporal budget line works in practice. Overall, the intertemporal budget line is a useful tool for analyzing the intertemporal allocation of resources and understanding how individuals make choices between present and future consumption. However, the given text does not contain information on the intertemporal budget line. It primarily deals with the capital asset pricing model, its assumptions, and their economic interpretations. It also discusses the use of assumptions in economics to establish knowledge about how markets set prices and the empirical verification of theoretical models, including the failures of the capital asset pricing model to explain certain phenomena. The text also covers other topics such as futures contracts, bonds, initial public offerings, mutual funds, and the pricing of newly issued securities.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/desktop/eco.pdf\")\n",
    "prompt = \"Summarize the topic on the intertemporal budget line.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/Desktop/test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to extract questions and their respective answers from the given texts. Output them in the given format: \\n\\n Question: \\n Answer: \\n\"},\n",
    "            {\"role\": \"user\", \"content\":f\"{text_body[:-9000]}\"}\n",
    "        ]\n",
    "    )\n",
    "output = parse_results(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the purpose of this document?\n",
      "Answer: This document provides solutions to the STA130 Winter 2023 Midterm Examination, including questions related to R and Statistics Basics, Manipulating Data Tables in R and other related topics.\n",
      "\n",
      "Question: What are the instructions for the examination?\n",
      "Answer: The instructions for the examination include using a pencil instead of a pen, not using any calculators or other resources during the exam, and not taking any items with you if you leave the room before turning in your exam. \n",
      "\n",
      "Question: What is the error in the code provided in Question 1 and how can it be fixed?\n",
      "Answer: The code provided in Question 1 has at least three errors. The first error is that no value has been assigned for N. The second error is that tidyverse has not been loaded and cannot be used. The third error is incorrect syntax for glimpse and as_tibble. The errors can be fixed by assigning a value for N, installing and loading tidyverse if required, and removing the extra \"x\" in line two.\n",
      "\n",
      "Question: What are the descriptions for the distributions shown in Figure 1?\n",
      "Answer: Distribution (a) could be described as uniform with a large spread from 0 to 10. Distribution (b) could be described as symmetric with a center around 5. Distribution (c) could be described as bimodal with a very large spread. Distribution (d) could be described as unimodal but with a much narrower spread than (b).\n",
      "\n",
      "Question: What is a boxplot and what do the different components of a boxplot represent?\n",
      "Answer: A boxplot is a graphical summary of a set of data through their quartiles, displaying upper and lower quartiles and outliers. The central line represents the median; the box width represents the interquartile range; the whiskers represent the range of data outside the box, but within 1.5 times the interquartile range; and the individual data points represent outliers.\n",
      "\n",
      "Question: What is the purpose of the function filter() in R?\n",
      "Answer: The purpose of the function filter() in R is to subset a data table based on particular conditions, so that only the rows that meet those conditions are kept.\n",
      "\n",
      "Question: How can you compute the total number of athletes (n) competing in each sport along with the minimum, maximum, median, and interquartile range of their age, and output the result as a small tibble in R?\n",
      "Answer: To compute the total number of athletes (n) competing in each sport along with the minimum, maximum, median, and interquartile range of their age in R, you can use the functions group_by() and summarize(). The n = n() function can be used to compute the total number of athletes, while the statistical summaries can be computed using functions like mean(), min(), max(), median(), and quantile(). The summarize() function is used to compute these statistical summaries and group them by sport, while outputting the result as a tibble.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = []\n",
    "for qna_pair in output.split(\"\\n\\n\"):\n",
    "    q, a = qna_pair.split(\"\\n\")\n",
    "    q.remove(\"Question: \")\n",
    "    a.remove(\"Answer: \")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: To compute the total number of athletes (n) competing in each sport along with the minimum, maximum, median, and interquartile range of their age in R, you can use the functions group_by() and summarize(). The n = n() function can be used to compute the total number of athletes, while the statistical summaries can be computed using functions like mean(), min(), max(), median(), and quantile(). The summarize() function is used to compute these statistical summaries and group them by sport, while outputting the result as a tibble.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
