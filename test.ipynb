{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from utils import load_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = load_api_key(\"/Users/gursi/Desktop/openai-api.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_generator(chat_completion: openai.ChatCompletion, outline: dict[str, list[str]], level: str, subject: str):\n",
    "    prompt = engineer_prompt_note_gen(outline, level, subject)\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            # {\"role\": \"system\", \"content\":f\"Your are a {level} {subject} notes generator.\"},\n",
    "            {\"role\": \"system\", \"content\":f\"Your are a {level} {subject} notes generator. Generate notes in following format: \\n Topic heading: \\n \\t Notes...\"},\n",
    "            {\"role\": \"user\", \"content\":prompt}\n",
    "        ]\n",
    "    )\n",
    "    model_output = parse_results(model_output)\n",
    "    return model_output\n",
    "        \n",
    "    \n",
    "def engineer_prompt_note_gen(outline: dict[str, list[str]], level: str, subject: str):\n",
    "    prompt = f'Generate quick revision notes for me on the following topics for a {subject} course on a {level} level. Include all equations. Explain each variable and concept. Do not say \"sure, here are some notes..\".\\n\\n'\n",
    "    for topic in outline:\n",
    "        prompt += f\"- {topic}\\n\"\n",
    "        if outline[topic] is not None:\n",
    "            for subtopic in outline[topic]:\n",
    "                prompt += f\"    - {subtopic}\\n\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def parse_results(chatgpt_output: dict) -> str:\n",
    "    return chatgpt_output[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = load_api_key(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "chat_complete = openai.ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = {\n",
    "    \"Electromagnetism\":None,\n",
    "    \"Electricity\":[\n",
    "        \"Resistance\",\n",
    "        \"Energy and Power\",\n",
    "        \"Kirchoff Laws\",\n",
    "        \"Lenz laws\"\n",
    "    ],\n",
    "    \"Mechanics\": [\n",
    "        \"SUVAT equations\",\n",
    "        \"Terminal velocity\",\n",
    "        \"Friction and Drag\"\n",
    "    ]\n",
    "}\n",
    "output = note_generator(chat_complete, outline, \"High school\", \"Physics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electromagnetism:\n",
      "- Electromagnetic Force: A force of attraction or repulsion that acts between electrically charged particles or currents.\n",
      "- Electric charges: The fundamental property of matter that causes it to experience a force when placed in an electromagnetic field.\n",
      "- Magnetic field: A region around a magnetic material or moving electric charge within which the force of magnetism acts.\n",
      "Equation: F = qE + qv × B\n",
      "- Electromagnetic induction: A process where a conductor placed in a changing magnetic field causes a voltage to be induced across the conductor.\n",
      "Equation: ε = -dΦ/dt\n",
      "\n",
      "Electricity:\n",
      "- Resistance: The property of a material that opposes the flow of electric current through it.\n",
      "Equation: V = IR\n",
      "- Energy and Power: Energy is the ability to do work. Power is the rate at which work is done.\n",
      "Equations: E = Pt, P = VI\n",
      "- Kirchoff Laws: Two laws used for solving electrical circuits, namely the current law and the voltage law.\n",
      "Equations: ∑ I_in = ∑ I_out, ∑ V_loop = 0\n",
      "- Lenz laws: A law that states that an induced electric current in a conductor always flows in such a direction that it opposes the magnetic field that produced it.\n",
      "Equation: ε = −dΦ/dt\n",
      "\n",
      "Mechanics:\n",
      "- SUVAT equations: A set of equations that represent the relationship between distance, velocity, acceleration, and time\n",
      "Equations: v = u + at, s = ut + 1/2at^2, v^2 = u^2 + 2as, s = 1/2(u+v)t\n",
      "- Terminal velocity: The maximum speed that an object can reach when falling through a fluid (air or liquid)\n",
      "Equation: mg - kv = 0\n",
      "- Friction and Drag: Friction is a force that opposes motion between two surfaces in contact. Drag is a force that opposes motion through a fluid.\n",
      "Equations: F_friction = μN, F_drag = ½pv^2AC_d\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_results, parse_pdf, create_chat_object\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import openai\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_from_prompt(chat_completion: openai.ChatCompletion, prompt: str):\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to extract key words from text. Generic words should never be extracted, only topic specific words.\"},\n",
    "            {\"role\": \"user\", \"content\":f\"Extract the keywords from the following instruction. Output a single list of comma separated values only once. \\n\\n {prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    return output.split(\",\")\n",
    "\n",
    "def generate_single_summary(chat_completion: openai.ChatCompletion, input_text: str, summary_prompt: str) -> str:\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to summarize text based on a prompt. If relevant data is not found, return nothing.\"},\n",
    "            {\"role\": \"user\", \"content\":f\"{input_text} \\n\\n {summary_prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    return output\n",
    "\n",
    "def generate_summary(\n",
    "        chat_completion: openai.ChatCompletion,\n",
    "        text_body: str,\n",
    "        prompt: str,\n",
    "        buffer: int = 600\n",
    ") -> str:\n",
    "    keywords = extract_keywords_from_prompt(chat_completion, prompt)\n",
    "    keywords = [k.translate(str.maketrans('', '', string.punctuation)).strip().lower() for k in keywords]\n",
    "    print(f\"{len(keywords)} keywords found...\")\n",
    "    kw = []\n",
    "    [[kw.append(w) for w in word.split(\" \")] for word in keywords]\n",
    "    arr_text = np.array(text_body.lower().split())\n",
    "\n",
    "    print(\"Matching keywords in text...\")\n",
    "    idxs = np.array([])\n",
    "    max_idx = len(arr_text)\n",
    "    for keyw in kw:\n",
    "        kw_idxs = np.where(arr_text == keyw)[0] / max_idx\n",
    "        idxs = np.concatenate([idxs, kw_idxs])\n",
    "\n",
    "    print(\"Clustering...\")\n",
    "    kmeans = KMeans(n_clusters = len(keywords))\n",
    "    _ = kmeans.fit_predict(idxs.reshape(-1, 1))\n",
    "    centroid_idxs = list((kmeans.cluster_centers_ * len(arr_text)).astype(int).reshape(-1))\n",
    "\n",
    "    print(\"Generating summary...\")\n",
    "    summaries = []\n",
    "    for centroid_idx in centroid_idxs:\n",
    "        text_input = list(arr_text[max(0, centroid_idx - buffer):min(len(arr_text), centroid_idx + buffer)])\n",
    "        text_input = \" \".join(text_input)\n",
    "        summary = generate_single_summary(chat_completion, text_input, prompt)\n",
    "        summaries.append(summary)\n",
    "    summaries = \" \".join(summaries)\n",
    "    final_summary = generate_single_summary(chat_completion, summaries, prompt)\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "The study used an artificial neural system that separated image content from style using a VGG neural network and optimizing the white noise image through gradient descent. The loss function included a squared-error loss for feature representation and a mean-squared distance for style representation, with adjustable trade-off between the two. The model architecture consisted of 16 convolutional and 5 pooling layers, with max-pooling replaced by average pooling for image synthesis. Fully connected layers were not used, and the model was publicly available in the Caffe framework. The weighting factors for the contribution of each layer to the total loss were also included.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/Desktop/nst.pdf\")\n",
    "prompt = \"Summarize the loss function, optimization method and model architecture used in this study for me.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "Linear dependence and independence refer to whether a set of vectors can be expressed as linear combinations of each other or not. A basis for a subspace is a set of linearly independent vectors that span the subspace. Bases are not unique, but they all have the same number of vectors, called the dimension of the subspace, which tells us the maximum number of linearly independent vectors that can exist in the subspace. Linear independence is important in determining solutions to systems of linear equations and in finding bases and dimensions of vector spaces.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/desktop/223.pdf\")\n",
    "prompt = \"Summarize linear dependence and independence for me.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "The intertemporal budget line is a concept that represents the trade-off between current and future consumption. It shows the different combinations of present and future goods that a consumer can afford given their income and the interest rate. The slope of the line represents the opportunity cost of present consumption in terms of future consumption, and the intercepts represent the maximum levels of current and future consumption. The economic interpretation of the intercepts is that they represent the present value of future income or the future value of current income. A numerical example is provided to illustrate how the intertemporal budget line works in practice. Overall, the intertemporal budget line is a useful tool for analyzing the intertemporal allocation of resources and understanding how individuals make choices between present and future consumption. However, the given text does not contain information on the intertemporal budget line. It primarily deals with the capital asset pricing model, its assumptions, and their economic interpretations. It also discusses the use of assumptions in economics to establish knowledge about how markets set prices and the empirical verification of theoretical models, including the failures of the capital asset pricing model to explain certain phenomena. The text also covers other topics such as futures contracts, bonds, initial public offerings, mutual funds, and the pricing of newly issued securities.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/desktop/eco.pdf\")\n",
    "prompt = \"Summarize the topic on the intertemporal budget line.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/Desktop/test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to extract questions and their respective answers from the given texts. Output them in the given format: \\n\\n Question: \\n Answer: \\n\"},\n",
    "            {\"role\": \"user\", \"content\":f\"{text_body[:-9000]} \\n\\n Make sure to extract questions and their answers.\"}\n",
    "        ]\n",
    "    )\n",
    "output = parse_results(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What are the instructions for the STA130 Winter 2023 Midterm Examination?\n",
      "\n",
      "Answer:\n",
      "All answers submitted must be original. Students are recommended to use a pencil. No calculators, electronics, or resources are permitted during the exam. Students are not allowed to take any items with them if they leave the exam room before turning in their exam.\n",
      "\n",
      "Question:\n",
      "What is the reason for the error in the code block provided in section 1 question 1 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "There are at least three errors in the code snippet provided. The error is due to the fact that no value has been assigned for N, the lack of tidyverse being loaded, and the incorrect syntax for glimpse and as_tibble. \n",
      "\n",
      "Question:\n",
      "What are the types of distributions shown in Figure 1 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "Distribution (a) is uniform with a large spread from 0 to 10. Distribution (b) is symmetric with a center around 5. Distribution (c) is bimodal with a very large spread. Distribution (d) is unimodal but with a much narrower spread than (b).\n",
      "\n",
      "Question:\n",
      "How many observations and variables are included in the tibble oly12 in question 9 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "There are 10,384 observations and 14 variables included in tibble oly12.\n",
      "\n",
      "Question:\n",
      "What is the purpose of the NA values in the DOB field in question 10 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "The NA values in the DOB field indicate missing entries in the data table, which could cause problems if column or row operations with them. Therefore, it is necessary to remove them using filter() combined with is.na().\n",
      "\n",
      "Question:\n",
      "How would one go about creating a new data table from the tibble oly12 containing only athletes from countries that fielded athletes in two Sport entries: \"Badminton\" and \"Table Tennis\" in question 11 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "Using the filter() function with a logical or comparison (Sport == \"Badminton\" | Sport == \"Table Tennis\").\n",
      "\n",
      "Question:\n",
      "What is the purpose of the code block given in question 12 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "The code block is used to plot the age for each athlete group as a pair boxplot and colour it based on the Sport variable.\n",
      "\n",
      "Question:\n",
      "How would one go about summarizing the number of athletes competing in each sport, along with their minimum, maximum, median, and interquartile range of their age, then outputting the result as a small tibble in question 13 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "By using group_by() to group people together, followed by the summarize() function to compute the total number of athletes using the n = n() function and other statistics such as the median using statistic(Age) for all categories except for the IQR, which requires quantile(Age, c(0.25, 0.75)). \n",
      "\n",
      "Question:\n",
      "What is the purpose of the computed columns medal_points and eff_medals_p in question 14 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "The medal_points computed columns assign a gold medal 3 points, a silver medal 2 points, and a bronze medal one point, while the eff_medals_p column computes the count of medals earned, as well as the median and total medal points earned for each athlete.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_questions_answers(chat_completion: openai.ChatCompletion, text_body: str, div_length: int = 5000) -> dict[str, str]:\n",
    "    output_strs = \"\"\n",
    "    for i in range(1, (len(text_body) // div_length) + 2):\n",
    "        x = i * div_length\n",
    "        substr = text_body[(x - i):x]\n",
    "        model_output = chat_completion.create(\n",
    "            model = \"gpt-3.5-turbo\",\n",
    "            messages = [\n",
    "                # {\"role\": \"system\", \"content\":f\"Your job is to extract suspected questions and their answers from the given text. Output them in the given format: \\n\\n Question: \\n Answer: \\n\"},\n",
    "                # {\"role\": \"user\", \"content\":f\"Find and extract question and answer pairs from this test: {text_body}\"}\n",
    "                {\"role\": \"system\", \"content\":f\"Your task is to analyze a given text and extract questions along with their respective answers. While examining the text, ensure that you pay close attention to accuracy, clarity, and any specific formatting requirements within the text. If a question contains unique elements like programming code or math equations, make sure to include those in your output as well. Present your findings using the following format: Question: [Insert extracted question here] Answer: [Insert corresponding answer here] While maintaining the original meaning of both questions and answers, demonstrate flexibility and creativity in extracting information from various types of texts (e.g., articles, interviews, forums). Your response should be adaptable enough to capture unique insights found within different sources while still accurately presenting the extracted data. Please provide at least three examples of questions and answers extracted from the provided text.\"},\n",
    "                {\"role\": \"user\", \"content\":f\"{substr} \\n\\n Make sure to extract questions and their answers.\"}\n",
    "            ]\n",
    "        )\n",
    "        output = parse_results(model_output)\n",
    "        output_strs += output + \"\\n\\n\"\n",
    "\n",
    "    # output_dict = {}\n",
    "    # for qna_pair in output.split(\"Question:\"):\n",
    "    #     if qna_pair != \"\":\n",
    "    #         q, a = qna_pair.split(\"Answer:\")\n",
    "    #         q, a = q.strip(), a.strip()\n",
    "    #         output_dict[q] = a\n",
    "    # return output_dict\n",
    "    return output_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m2/jysgcgj57vn69541g8m0qz_h0000gn/T/ipykernel_21938/1733780992.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/gursi/Desktop/test.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_questions_answers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_completion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/m2/jysgcgj57vn69541g8m0qz_h0000gn/T/ipykernel_21938/304669256.py\u001b[0m in \u001b[0;36mread_questions_answers\u001b[0;34m(chat_completion, text_body, div_length)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiv_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msubstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_body\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         model_output = chat_completion.create(\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             messages = [\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], bool, str]:\n\u001b[0;32m--> 216\u001b[0;31m         result = self.request_raw(\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0m_thread_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             result = _thread_context.session.request(\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mabs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    441\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/hackathon/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/Desktop/test.pdf\")\n",
    "output_dict = read_questions_answers(chat_completion, text_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'What are the instructions for the STA130 Winter 2023 Midterm Examination?': 'The instructions include using a pencil for the examination, not using calculators or electronic devices, and not taking any items if leaving the room before turning in the exam. No questions or clarifications will be provided during the exam.',\n",
       " 'What are the errors in the given R code: \"x<-1:N x%>% as_tibble (x) %>% glimpse (x)\"?': 'There are at least 3 errors in the given R code. First, there is'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Out of 100): 20\n",
      "Feedback: Unfortunately, your answer is not correct as you have provided the answer for a different question. The question asks about errors in the given R code, but your answer talks about missing values in a field. Please read the question carefully and try again.\n"
     ]
    }
   ],
   "source": [
    "sample_question = list(output_dict.keys())[1]\n",
    "expected_answer = output_dict[sample_question]\n",
    "my_answer = \"Missing values in the DOB field are represented with the NA values. The code will not produce correct outputs if these are not removed. You would remove them using the is.na() and filter() functions in R.\"\n",
    "\n",
    "def grade_answer(chat_completion: openai.ChatCompletion, question: str, my_answer: str, correct_answer: str) -> str:\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"You are a teacher and your job is to grade my answer based on the Expected Answer and Question. My answer need not exactly match the Expected Answer. Give your output in the following format: \\n Score (Out of 100): \\n Feedback: ...\\n\"},\n",
    "            {\"role\": \"user\", \"content\":f\"Question: {question} \\n Expected Answer: {correct_answer} \\n My answer: {my_answer}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    return output\n",
    "\n",
    "print(grade_answer(chat_completion, sample_question, my_answer, expected_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade weightages/Breakdown:\n",
      "- Reading assignments - 14%\n",
      "- Online standards-based homework - 15%\n",
      "- Group reports - 30%\n",
      "- Individual reflective writing assignments - 6%\n",
      "- In-person final exam or final project - 35%\n",
      "\n",
      "Office Hours: Not specified\n",
      "\n",
      "Mandatory Attendance: Not specified\n",
      "\n",
      "Late submission policy:\n",
      "- Late reading assignments will not be accepted.\n",
      "- MathMatize homework assignments must be completed by the due dates listed above. Students, however, should complete the assignments during the week they are assigned in order to stay current with the material.\n",
      "- Late group reports are not accepted except for special circumstances.\n",
      "\n",
      "Regrading policy: Grade resubmission is allowed only for group reports once without penalty. The higher of the original score and resubmitted score will be used for course marks.\n"
     ]
    }
   ],
   "source": [
    "def generate_syllabus(chat_completion: openai.ChatCompletion, text_body: str, div_length: int = 5000) -> str:\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to read the information and extract the Grade Weightages, Office Hour timings, whther or not the course has mandatory attendance, the late submission policy and the regrading policy and output it in the given format:\\n\\n - Grade weightages/Breakdown: \\n  - Component 1 - X% \\n   - Component 2 - X% \\n Office Hours: \\n Mandatory Attendance: <Yes/No>\\n Late submissing policy: \\n Regrading policy: \"},\n",
    "            {\"role\": \"user\", \"content\":f\"{text_body}\"}\n",
    "            ]\n",
    "        )\n",
    "    output = parse_results(model_output)\n",
    "    return output\n",
    "\n",
    "text_body = parse_pdf(\"/Users/gursi/Desktop/223-syl.pdf\")\n",
    "output = generate_syllabus(chat_completion, text_body)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
