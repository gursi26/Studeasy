{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from utils import load_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = load_api_key(\"/Users/gursi/Desktop/openai-api.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_generator(chat_completion: openai.ChatCompletion, outline: dict[str, list[str]], level: str, subject: str):\n",
    "    prompt = engineer_prompt_note_gen(outline, level, subject)\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            # {\"role\": \"system\", \"content\":f\"Your are a {level} {subject} notes generator.\"},\n",
    "            {\"role\": \"system\", \"content\":f\"Your are a {level} {subject} notes generator. Generate notes in following format: \\n Topic heading: \\n \\t Notes...\"},\n",
    "            {\"role\": \"user\", \"content\":prompt}\n",
    "        ]\n",
    "    )\n",
    "    model_output = parse_results(model_output)\n",
    "    return model_output\n",
    "        \n",
    "    \n",
    "def engineer_prompt_note_gen(outline: dict[str, list[str]], level: str, subject: str):\n",
    "    prompt = f'Generate quick revision notes for me on the following topics for a {subject} course on a {level} level. Include all equations. Explain each variable and concept. Do not say \"sure, here are some notes..\".\\n\\n'\n",
    "    for topic in outline:\n",
    "        prompt += f\"- {topic}\\n\"\n",
    "        if outline[topic] is not None:\n",
    "            for subtopic in outline[topic]:\n",
    "                prompt += f\"    - {subtopic}\\n\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def parse_results(chatgpt_output: dict) -> str:\n",
    "    return chatgpt_output[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = load_api_key(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "chat_complete = openai.ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = {\n",
    "    \"Electromagnetism\":None,\n",
    "    \"Electricity\":[\n",
    "        \"Resistance\",\n",
    "        \"Energy and Power\",\n",
    "        \"Kirchoff Laws\",\n",
    "        \"Lenz laws\"\n",
    "    ],\n",
    "    \"Mechanics\": [\n",
    "        \"SUVAT equations\",\n",
    "        \"Terminal velocity\",\n",
    "        \"Friction and Drag\"\n",
    "    ]\n",
    "}\n",
    "output = note_generator(chat_complete, outline, \"High school\", \"Physics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electromagnetism:\n",
      "- Electromagnetic Force: A force of attraction or repulsion that acts between electrically charged particles or currents.\n",
      "- Electric charges: The fundamental property of matter that causes it to experience a force when placed in an electromagnetic field.\n",
      "- Magnetic field: A region around a magnetic material or moving electric charge within which the force of magnetism acts.\n",
      "Equation: F = qE + qv × B\n",
      "- Electromagnetic induction: A process where a conductor placed in a changing magnetic field causes a voltage to be induced across the conductor.\n",
      "Equation: ε = -dΦ/dt\n",
      "\n",
      "Electricity:\n",
      "- Resistance: The property of a material that opposes the flow of electric current through it.\n",
      "Equation: V = IR\n",
      "- Energy and Power: Energy is the ability to do work. Power is the rate at which work is done.\n",
      "Equations: E = Pt, P = VI\n",
      "- Kirchoff Laws: Two laws used for solving electrical circuits, namely the current law and the voltage law.\n",
      "Equations: ∑ I_in = ∑ I_out, ∑ V_loop = 0\n",
      "- Lenz laws: A law that states that an induced electric current in a conductor always flows in such a direction that it opposes the magnetic field that produced it.\n",
      "Equation: ε = −dΦ/dt\n",
      "\n",
      "Mechanics:\n",
      "- SUVAT equations: A set of equations that represent the relationship between distance, velocity, acceleration, and time\n",
      "Equations: v = u + at, s = ut + 1/2at^2, v^2 = u^2 + 2as, s = 1/2(u+v)t\n",
      "- Terminal velocity: The maximum speed that an object can reach when falling through a fluid (air or liquid)\n",
      "Equation: mg - kv = 0\n",
      "- Friction and Drag: Friction is a force that opposes motion between two surfaces in contact. Drag is a force that opposes motion through a fluid.\n",
      "Equations: F_friction = μN, F_drag = ½pv^2AC_d\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_results, parse_pdf, create_chat_object\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import openai\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_from_prompt(chat_completion: openai.ChatCompletion, prompt: str):\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to extract key words from text. Generic words should never be extracted, only topic specific words.\"},\n",
    "            {\"role\": \"user\", \"content\":f\"Extract the keywords from the following instruction. Output a single list of comma separated values only once. \\n\\n {prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    return output.split(\",\")\n",
    "\n",
    "def generate_single_summary(chat_completion: openai.ChatCompletion, input_text: str, summary_prompt: str) -> str:\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to summarize text based on a prompt. If relevant data is not found, return nothing.\"},\n",
    "            {\"role\": \"user\", \"content\":f\"{input_text} \\n\\n {summary_prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    return output\n",
    "\n",
    "def generate_summary(\n",
    "        chat_completion: openai.ChatCompletion,\n",
    "        text_body: str,\n",
    "        prompt: str,\n",
    "        buffer: int = 600\n",
    ") -> str:\n",
    "    keywords = extract_keywords_from_prompt(chat_completion, prompt)\n",
    "    keywords = [k.translate(str.maketrans('', '', string.punctuation)).strip().lower() for k in keywords]\n",
    "    print(f\"{len(keywords)} keywords found...\")\n",
    "    kw = []\n",
    "    [[kw.append(w) for w in word.split(\" \")] for word in keywords]\n",
    "    arr_text = np.array(text_body.lower().split())\n",
    "\n",
    "    print(\"Matching keywords in text...\")\n",
    "    idxs = np.array([])\n",
    "    max_idx = len(arr_text)\n",
    "    for keyw in kw:\n",
    "        kw_idxs = np.where(arr_text == keyw)[0] / max_idx\n",
    "        idxs = np.concatenate([idxs, kw_idxs])\n",
    "\n",
    "    print(\"Clustering...\")\n",
    "    kmeans = KMeans(n_clusters = len(keywords))\n",
    "    _ = kmeans.fit_predict(idxs.reshape(-1, 1))\n",
    "    centroid_idxs = list((kmeans.cluster_centers_ * len(arr_text)).astype(int).reshape(-1))\n",
    "\n",
    "    print(\"Generating summary...\")\n",
    "    summaries = []\n",
    "    for centroid_idx in centroid_idxs:\n",
    "        text_input = list(arr_text[max(0, centroid_idx - buffer):min(len(arr_text), centroid_idx + buffer)])\n",
    "        text_input = \" \".join(text_input)\n",
    "        summary = generate_single_summary(chat_completion, text_input, prompt)\n",
    "        summaries.append(summary)\n",
    "    summaries = \" \".join(summaries)\n",
    "    final_summary = generate_single_summary(chat_completion, summaries, prompt)\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "The study used an artificial neural system that separated image content from style using a VGG neural network and optimizing the white noise image through gradient descent. The loss function included a squared-error loss for feature representation and a mean-squared distance for style representation, with adjustable trade-off between the two. The model architecture consisted of 16 convolutional and 5 pooling layers, with max-pooling replaced by average pooling for image synthesis. Fully connected layers were not used, and the model was publicly available in the Caffe framework. The weighting factors for the contribution of each layer to the total loss were also included.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/Desktop/nst.pdf\")\n",
    "prompt = \"Summarize the loss function, optimization method and model architecture used in this study for me.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "Linear dependence and independence refer to whether a set of vectors can be expressed as linear combinations of each other or not. A basis for a subspace is a set of linearly independent vectors that span the subspace. Bases are not unique, but they all have the same number of vectors, called the dimension of the subspace, which tells us the maximum number of linearly independent vectors that can exist in the subspace. Linear independence is important in determining solutions to systems of linear equations and in finding bases and dimensions of vector spaces.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/desktop/223.pdf\")\n",
    "prompt = \"Summarize linear dependence and independence for me.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "The intertemporal budget line is a concept that represents the trade-off between current and future consumption. It shows the different combinations of present and future goods that a consumer can afford given their income and the interest rate. The slope of the line represents the opportunity cost of present consumption in terms of future consumption, and the intercepts represent the maximum levels of current and future consumption. The economic interpretation of the intercepts is that they represent the present value of future income or the future value of current income. A numerical example is provided to illustrate how the intertemporal budget line works in practice. Overall, the intertemporal budget line is a useful tool for analyzing the intertemporal allocation of resources and understanding how individuals make choices between present and future consumption. However, the given text does not contain information on the intertemporal budget line. It primarily deals with the capital asset pricing model, its assumptions, and their economic interpretations. It also discusses the use of assumptions in economics to establish knowledge about how markets set prices and the empirical verification of theoretical models, including the failures of the capital asset pricing model to explain certain phenomena. The text also covers other topics such as futures contracts, bonds, initial public offerings, mutual funds, and the pricing of newly issued securities.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/desktop/eco.pdf\")\n",
    "prompt = \"Summarize the topic on the intertemporal budget line.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/Desktop/test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to extract questions and their respective answers from the given texts. Output them in the given format: \\n\\n Question: \\n Answer: \\n\"},\n",
    "            {\"role\": \"user\", \"content\":f\"{text_body[:-9000]} \\n\\n Make sure to extract questions and their answers.\"}\n",
    "        ]\n",
    "    )\n",
    "output = parse_results(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What are the instructions for the STA130 Winter 2023 Midterm Examination?\n",
      "\n",
      "Answer:\n",
      "All answers submitted must be original. Students are recommended to use a pencil. No calculators, electronics, or resources are permitted during the exam. Students are not allowed to take any items with them if they leave the exam room before turning in their exam.\n",
      "\n",
      "Question:\n",
      "What is the reason for the error in the code block provided in section 1 question 1 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "There are at least three errors in the code snippet provided. The error is due to the fact that no value has been assigned for N, the lack of tidyverse being loaded, and the incorrect syntax for glimpse and as_tibble. \n",
      "\n",
      "Question:\n",
      "What are the types of distributions shown in Figure 1 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "Distribution (a) is uniform with a large spread from 0 to 10. Distribution (b) is symmetric with a center around 5. Distribution (c) is bimodal with a very large spread. Distribution (d) is unimodal but with a much narrower spread than (b).\n",
      "\n",
      "Question:\n",
      "How many observations and variables are included in the tibble oly12 in question 9 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "There are 10,384 observations and 14 variables included in tibble oly12.\n",
      "\n",
      "Question:\n",
      "What is the purpose of the NA values in the DOB field in question 10 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "The NA values in the DOB field indicate missing entries in the data table, which could cause problems if column or row operations with them. Therefore, it is necessary to remove them using filter() combined with is.na().\n",
      "\n",
      "Question:\n",
      "How would one go about creating a new data table from the tibble oly12 containing only athletes from countries that fielded athletes in two Sport entries: \"Badminton\" and \"Table Tennis\" in question 11 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "Using the filter() function with a logical or comparison (Sport == \"Badminton\" | Sport == \"Table Tennis\").\n",
      "\n",
      "Question:\n",
      "What is the purpose of the code block given in question 12 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "The code block is used to plot the age for each athlete group as a pair boxplot and colour it based on the Sport variable.\n",
      "\n",
      "Question:\n",
      "How would one go about summarizing the number of athletes competing in each sport, along with their minimum, maximum, median, and interquartile range of their age, then outputting the result as a small tibble in question 13 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "By using group_by() to group people together, followed by the summarize() function to compute the total number of athletes using the n = n() function and other statistics such as the median using statistic(Age) for all categories except for the IQR, which requires quantile(Age, c(0.25, 0.75)). \n",
      "\n",
      "Question:\n",
      "What is the purpose of the computed columns medal_points and eff_medals_p in question 14 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "The medal_points computed columns assign a gold medal 3 points, a silver medal 2 points, and a bronze medal one point, while the eff_medals_p column computes the count of medals earned, as well as the median and total medal points earned for each athlete.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_questions_answers(chat_completion: openai.ChatCompletion, text_body: str) -> dict[str, str]:\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            # {\"role\": \"system\", \"content\":f\"Your job is to extract suspected questions and their answers from the given text. Output them in the given format: \\n\\n Question: \\n Answer: \\n\"},\n",
    "            # {\"role\": \"user\", \"content\":f\"Find and extract question and answer pairs from this test: {text_body}\"}\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to extract questions and their respective answers from the given texts. Output them in the given format: \\n\\n Question: \\n Answer: \\n\"},\n",
    "            {\"role\": \"user\", \"content\":f\"{text_body[:-9000]} \\n\\n Make sure to extract questions and their answers.\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    print(output)\n",
    "    output_dict = {}\n",
    "    for qna_pair in output.split(\"Question:\"):\n",
    "        if qna_pair != \"\":\n",
    "            q, a = qna_pair.split(\"Answer:\")\n",
    "            q, a = q.strip(), a.strip()\n",
    "            output_dict[q] = a\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the three errors in the code block in Question 1, and how can they be fixed?\n",
      "Answer: The three errors are: N has not been assigned a value, tidyverse package is not loaded in and cannot be used, and there is a syntax error in the glimpse and as_tibble functions. N can be assigned a value, tidyverse can be installed and loaded in, and the syntax error can be fixed by removing the extra \"x\" in line two.\n",
      "\n",
      "Question: Are the statements (i) Vectors can contain elements of different variable\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m2/jysgcgj57vn69541g8m0qz_h0000gn/T/ipykernel_21938/1733780992.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/gursi/Desktop/test.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_questions_answers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_completion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/m2/jysgcgj57vn69541g8m0qz_h0000gn/T/ipykernel_21938/2564972824.py\u001b[0m in \u001b[0;36mread_questions_answers\u001b[0;34m(chat_completion, text_body)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mqna_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Question:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mqna_pair\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqna_pair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/Desktop/test.pdf\")\n",
    "output_dict = read_questions_answers(chat_completion, text_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'What are the instructions for the STA130 Winter 2023 Midterm Examination?': 'The instructions include using a pencil for the examination, not using calculators or electronic devices, and not taking any items if leaving the room before turning in the exam. No questions or clarifications will be provided during the exam.',\n",
       " 'What are the errors in the given R code: \"x<-1:N x%>% as_tibble (x) %>% glimpse (x)\"?': 'There are at least 3 errors in the given R code. First, there is'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Out of 100): 20\n",
      "Feedback: Unfortunately, your answer is not correct as you have provided the answer for a different question. The question asks about errors in the given R code, but your answer talks about missing values in a field. Please read the question carefully and try again.\n"
     ]
    }
   ],
   "source": [
    "sample_question = list(output_dict.keys())[1]\n",
    "expected_answer = output_dict[sample_question]\n",
    "my_answer = \"Missing values in the DOB field are represented with the NA values. The code will not produce correct outputs if these are not removed. You would remove them using the is.na() and filter() functions in R.\"\n",
    "\n",
    "def grade_answer(chat_completion: openai.ChatCompletion, question: str, my_answer: str, correct_answer: str) -> str:\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"You are a teacher and your job is to grade my answer based on the Expected Answer and Question. My answer need not exactly match the Expected Answer. Give your output in the following format: \\n Score (Out of 100): \\n Feedback: ...\\n\"},\n",
    "            {\"role\": \"user\", \"content\":f\"Question: {question} \\n Expected Answer: {correct_answer} \\n My answer: {my_answer}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    return output\n",
    "\n",
    "print(grade_answer(chat_completion, sample_question, my_answer, expected_answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
