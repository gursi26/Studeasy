{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from utils import load_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = load_api_key(\"/Users/gursi/Desktop/openai-api.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_generator(chat_completion: openai.ChatCompletion, outline: dict[str, list[str]], level: str, subject: str):\n",
    "    prompt = engineer_prompt_note_gen(outline, level, subject)\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            # {\"role\": \"system\", \"content\":f\"Your are a {level} {subject} notes generator.\"},\n",
    "            {\"role\": \"system\", \"content\":f\"Your are a {level} {subject} notes generator. Generate notes in following format: \\n Topic heading: \\n \\t Notes...\"},\n",
    "            {\"role\": \"user\", \"content\":prompt}\n",
    "        ]\n",
    "    )\n",
    "    model_output = parse_results(model_output)\n",
    "    return model_output\n",
    "        \n",
    "    \n",
    "def engineer_prompt_note_gen(outline: dict[str, list[str]], level: str, subject: str):\n",
    "    prompt = f'Generate quick revision notes for me on the following topics for a {subject} course on a {level} level. Include all equations. Explain each variable and concept. Do not say \"sure, here are some notes..\".\\n\\n'\n",
    "    for topic in outline:\n",
    "        prompt += f\"- {topic}\\n\"\n",
    "        if outline[topic] is not None:\n",
    "            for subtopic in outline[topic]:\n",
    "                prompt += f\"    - {subtopic}\\n\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def parse_results(chatgpt_output: dict) -> str:\n",
    "    return chatgpt_output[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = load_api_key(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "chat_complete = openai.ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = {\n",
    "    \"Electromagnetism\":None,\n",
    "    \"Electricity\":[\n",
    "        \"Resistance\",\n",
    "        \"Energy and Power\",\n",
    "        \"Kirchoff Laws\",\n",
    "        \"Lenz laws\"\n",
    "    ],\n",
    "    \"Mechanics\": [\n",
    "        \"SUVAT equations\",\n",
    "        \"Terminal velocity\",\n",
    "        \"Friction and Drag\"\n",
    "    ]\n",
    "}\n",
    "output = note_generator(chat_complete, outline, \"High school\", \"Physics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electromagnetism:\n",
      "- Electromagnetic Force: A force of attraction or repulsion that acts between electrically charged particles or currents.\n",
      "- Electric charges: The fundamental property of matter that causes it to experience a force when placed in an electromagnetic field.\n",
      "- Magnetic field: A region around a magnetic material or moving electric charge within which the force of magnetism acts.\n",
      "Equation: F = qE + qv × B\n",
      "- Electromagnetic induction: A process where a conductor placed in a changing magnetic field causes a voltage to be induced across the conductor.\n",
      "Equation: ε = -dΦ/dt\n",
      "\n",
      "Electricity:\n",
      "- Resistance: The property of a material that opposes the flow of electric current through it.\n",
      "Equation: V = IR\n",
      "- Energy and Power: Energy is the ability to do work. Power is the rate at which work is done.\n",
      "Equations: E = Pt, P = VI\n",
      "- Kirchoff Laws: Two laws used for solving electrical circuits, namely the current law and the voltage law.\n",
      "Equations: ∑ I_in = ∑ I_out, ∑ V_loop = 0\n",
      "- Lenz laws: A law that states that an induced electric current in a conductor always flows in such a direction that it opposes the magnetic field that produced it.\n",
      "Equation: ε = −dΦ/dt\n",
      "\n",
      "Mechanics:\n",
      "- SUVAT equations: A set of equations that represent the relationship between distance, velocity, acceleration, and time\n",
      "Equations: v = u + at, s = ut + 1/2at^2, v^2 = u^2 + 2as, s = 1/2(u+v)t\n",
      "- Terminal velocity: The maximum speed that an object can reach when falling through a fluid (air or liquid)\n",
      "Equation: mg - kv = 0\n",
      "- Friction and Drag: Friction is a force that opposes motion between two surfaces in contact. Drag is a force that opposes motion through a fluid.\n",
      "Equations: F_friction = μN, F_drag = ½pv^2AC_d\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_results, parse_pdf, create_chat_object\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import openai\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_from_prompt(chat_completion: openai.ChatCompletion, prompt: str):\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to extract key words from text. Generic words should never be extracted, only topic specific words.\"},\n",
    "            {\"role\": \"user\", \"content\":f\"Extract the keywords from the following instruction. Output a single list of comma separated values only once. \\n\\n {prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    return output.split(\",\")\n",
    "\n",
    "def generate_single_summary(chat_completion: openai.ChatCompletion, input_text: str, summary_prompt: str) -> str:\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to summarize text based on a prompt. If relevant data is not found, return nothing.\"},\n",
    "            {\"role\": \"user\", \"content\":f\"{input_text} \\n\\n {summary_prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n",
    "    return output\n",
    "\n",
    "def generate_summary(\n",
    "        chat_completion: openai.ChatCompletion,\n",
    "        text_body: str,\n",
    "        prompt: str,\n",
    "        buffer: int = 600\n",
    ") -> str:\n",
    "    keywords = extract_keywords_from_prompt(chat_completion, prompt)\n",
    "    keywords = [k.translate(str.maketrans('', '', string.punctuation)).strip().lower() for k in keywords]\n",
    "    print(f\"{len(keywords)} keywords found...\")\n",
    "    kw = []\n",
    "    [[kw.append(w) for w in word.split(\" \")] for word in keywords]\n",
    "    arr_text = np.array(text_body.lower().split())\n",
    "\n",
    "    print(\"Matching keywords in text...\")\n",
    "    idxs = np.array([])\n",
    "    max_idx = len(arr_text)\n",
    "    for keyw in kw:\n",
    "        kw_idxs = np.where(arr_text == keyw)[0] / max_idx\n",
    "        idxs = np.concatenate([idxs, kw_idxs])\n",
    "\n",
    "    print(\"Clustering...\")\n",
    "    kmeans = KMeans(n_clusters = len(keywords))\n",
    "    _ = kmeans.fit_predict(idxs.reshape(-1, 1))\n",
    "    centroid_idxs = list((kmeans.cluster_centers_ * len(arr_text)).astype(int).reshape(-1))\n",
    "\n",
    "    print(\"Generating summary...\")\n",
    "    summaries = []\n",
    "    for centroid_idx in centroid_idxs:\n",
    "        text_input = list(arr_text[max(0, centroid_idx - buffer):min(len(arr_text), centroid_idx + buffer)])\n",
    "        text_input = \" \".join(text_input)\n",
    "        summary = generate_single_summary(chat_completion, text_input, prompt)\n",
    "        summaries.append(summary)\n",
    "    summaries = \" \".join(summaries)\n",
    "    final_summary = generate_single_summary(chat_completion, summaries, prompt)\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "The study used an artificial neural system that separated image content from style using a VGG neural network and optimizing the white noise image through gradient descent. The loss function included a squared-error loss for feature representation and a mean-squared distance for style representation, with adjustable trade-off between the two. The model architecture consisted of 16 convolutional and 5 pooling layers, with max-pooling replaced by average pooling for image synthesis. Fully connected layers were not used, and the model was publicly available in the Caffe framework. The weighting factors for the contribution of each layer to the total loss were also included.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/Desktop/nst.pdf\")\n",
    "prompt = \"Summarize the loss function, optimization method and model architecture used in this study for me.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "Linear dependence and independence refer to whether a set of vectors can be expressed as linear combinations of each other or not. A basis for a subspace is a set of linearly independent vectors that span the subspace. Bases are not unique, but they all have the same number of vectors, called the dimension of the subspace, which tells us the maximum number of linearly independent vectors that can exist in the subspace. Linear independence is important in determining solutions to systems of linear equations and in finding bases and dimensions of vector spaces.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/desktop/223.pdf\")\n",
    "prompt = \"Summarize linear dependence and independence for me.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 keywords found...\n",
      "Matching keywords in text...\n",
      "Clustering...\n",
      "Generating summary...\n",
      "The intertemporal budget line is a concept that represents the trade-off between current and future consumption. It shows the different combinations of present and future goods that a consumer can afford given their income and the interest rate. The slope of the line represents the opportunity cost of present consumption in terms of future consumption, and the intercepts represent the maximum levels of current and future consumption. The economic interpretation of the intercepts is that they represent the present value of future income or the future value of current income. A numerical example is provided to illustrate how the intertemporal budget line works in practice. Overall, the intertemporal budget line is a useful tool for analyzing the intertemporal allocation of resources and understanding how individuals make choices between present and future consumption. However, the given text does not contain information on the intertemporal budget line. It primarily deals with the capital asset pricing model, its assumptions, and their economic interpretations. It also discusses the use of assumptions in economics to establish knowledge about how markets set prices and the empirical verification of theoretical models, including the failures of the capital asset pricing model to explain certain phenomena. The text also covers other topics such as futures contracts, bonds, initial public offerings, mutual funds, and the pricing of newly issued securities.\n"
     ]
    }
   ],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/desktop/eco.pdf\")\n",
    "prompt = \"Summarize the topic on the intertemporal budget line.\"\n",
    "chat_completion = create_chat_object(\"/Users/gursi/Desktop/openai-api.txt\")\n",
    "summary = generate_summary(\n",
    "    chat_completion,\n",
    "    text_body,\n",
    "    prompt,\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_body = parse_pdf(\"/Users/gursi/Desktop/test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"Your job is to extract questions and their respective answers from the given texts. Output them in the given format: \\n\\n Question: \\n Answer: \\n\"},\n",
    "            {\"role\": \"user\", \"content\":f\"{text_body[:-9000]} \\n\\n Make sure to extract questions and their answers.\"}\n",
    "        ]\n",
    "    )\n",
    "output = parse_results(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "What are the instructions for the STA130 Winter 2023 Midterm Examination?\n",
      "\n",
      "Answer:\n",
      "All answers submitted must be original. Students are recommended to use a pencil. No calculators, electronics, or resources are permitted during the exam. Students are not allowed to take any items with them if they leave the exam room before turning in their exam.\n",
      "\n",
      "Question:\n",
      "What is the reason for the error in the code block provided in section 1 question 1 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "There are at least three errors in the code snippet provided. The error is due to the fact that no value has been assigned for N, the lack of tidyverse being loaded, and the incorrect syntax for glimpse and as_tibble. \n",
      "\n",
      "Question:\n",
      "What are the types of distributions shown in Figure 1 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "Distribution (a) is uniform with a large spread from 0 to 10. Distribution (b) is symmetric with a center around 5. Distribution (c) is bimodal with a very large spread. Distribution (d) is unimodal but with a much narrower spread than (b).\n",
      "\n",
      "Question:\n",
      "How many observations and variables are included in the tibble oly12 in question 9 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "There are 10,384 observations and 14 variables included in tibble oly12.\n",
      "\n",
      "Question:\n",
      "What is the purpose of the NA values in the DOB field in question 10 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "The NA values in the DOB field indicate missing entries in the data table, which could cause problems if column or row operations with them. Therefore, it is necessary to remove them using filter() combined with is.na().\n",
      "\n",
      "Question:\n",
      "How would one go about creating a new data table from the tibble oly12 containing only athletes from countries that fielded athletes in two Sport entries: \"Badminton\" and \"Table Tennis\" in question 11 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "Using the filter() function with a logical or comparison (Sport == \"Badminton\" | Sport == \"Table Tennis\").\n",
      "\n",
      "Question:\n",
      "What is the purpose of the code block given in question 12 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "The code block is used to plot the age for each athlete group as a pair boxplot and colour it based on the Sport variable.\n",
      "\n",
      "Question:\n",
      "How would one go about summarizing the number of athletes competing in each sport, along with their minimum, maximum, median, and interquartile range of their age, then outputting the result as a small tibble in question 13 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "By using group_by() to group people together, followed by the summarize() function to compute the total number of athletes using the n = n() function and other statistics such as the median using statistic(Age) for all categories except for the IQR, which requires quantile(Age, c(0.25, 0.75)). \n",
      "\n",
      "Question:\n",
      "What is the purpose of the computed columns medal_points and eff_medals_p in question 14 of section 2 of the STA130 Winter 2023 Midterm Exam?\n",
      "\n",
      "Answer:\n",
      "The medal_points computed columns assign a gold medal 3 points, a silver medal 2 points, and a bronze medal one point, while the eff_medals_p column computes the count of medals earned, as well as the median and total medal points earned for each athlete.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {}\n",
    "for qna_pair in output.split(\"Question:\"):\n",
    "    if qna_pair != \"\":\n",
    "        q, a = qna_pair.split(\"Answer:\")\n",
    "        q, a = q.strip(), a.strip()\n",
    "        output_dict[q] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = list(output_dict.keys())[4]\n",
    "expected_answer = output_dict[sample_question]\n",
    "my_answer = \"Missing values in the DOB field are represented with the NA values. The code will not produce correct outputs if these are not removed. You would remove them using the is.na() and filter() functions in R.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"You are a teacher and your job is to grade my answer based on the Expected Answer and Question. My answer need not exactly match the Expected Answer. Give your output in the following format: \\n Score (Out of 100): \\n Feedback: ...\\n\"},\n",
    "            {\"role\": \"user\", \"content\":f\"Question: {sample_question} \\n Expected Answer: {expected_answer} \\n My answer: {my_answer}\"}\n",
    "        ]\n",
    "    )\n",
    "output = parse_results(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Out of 100): 90 \n",
      "Feedback: Your answer is accurate and shows a good understanding of the purpose of NA values in the DOB field in question 10. However, it could have been more detailed and specific with regards to what can happen when these missing entries are not removed. Remember to provide clear and complete answers that demonstrate your knowledge of the subject matter.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_answer(question: str, answer: str, correct_answer: str) -> tuple[int, str]:\n",
    "    model_output = chat_completion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"You are a teacher and your job is to grade my answer based on the Expected Answer and Question. My answer need not exactly match the Expected Answer. Give your output in the following format: \\n Score (Out of 100): \\n Feedback: ...\\n\"},\n",
    "            {\"role\": \"user\", \"content\":f\"Question: {question} \\n Expected Answer: {correct_answer} \\n My answer: {answer}\"}\n",
    "        ]\n",
    "    )\n",
    "    output = parse_results(model_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
